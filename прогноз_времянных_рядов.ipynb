{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdp0UbdCOSGhGKamRI7AXd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammadsulton1/MIPT_Data_analys/blob/main/%D0%BF%D1%80%D0%BE%D0%B3%D0%BD%D0%BE%D0%B7_%D0%B2%D1%80%D0%B5%D0%BC%D1%8F%D0%BD%D0%BD%D1%8B%D1%85_%D1%80%D1%8F%D0%B4%D0%BE%D0%B2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyJEdX8-goaB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "4RfutxbLhanX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ads = pd.read_csv('data/ads.csv', index_col=['Time'], parse_dates=['Time']).asfreq('H')\n",
        "print(ads.shape)\n",
        "ads.head()"
      ],
      "metadata": {
        "id": "CGZ3LLCAhb7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sktime.utils.plotting import plot_series\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "y = ads.Ads/10**3  # в тысячах :)\n",
        "\n",
        "plot_series(y)\n",
        "plt.title('Просмотры рекламы (тыс. часов)', fontsize=20, color='black')\n",
        "plt.tick_params(axis = 'both', which = 'major', labelsize = 14);"
      ],
      "metadata": {
        "id": "LC8_oSoYhfmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Метрики качества прогноза\n",
        "Рассмотрим основные и самые распространенные метрики качества прогнозов, которые, по большому счету, являются метриками для задачи регрессии и используются далеко не только во временных рядах.\n",
        "\n",
        "Mean Absolute Error, интерпретируемая метрика, измеряется в тех же единицах, что и исходный ряд,\n",
        "\n",
        "\n",
        "sklearn.metrics.mean_absolute_error"
      ],
      "metadata": {
        "id": "TzRN2gb-hhYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Median Absolute Error, также интерпретируемая метрика, однако её преимущество - нечувствительность (робастность) к выбросам в данных,\n",
        "\n",
        "sklearn.metrics.median_absolute_error"
      ],
      "metadata": {
        "id": "GduYGQIDhkpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Squared Error, используется в большинстве случаев, сильнее наказывает модель за большие ошибки и меньше - за маленькие (парабола),\n",
        "\n",
        "\n",
        "sklearn.metrics.mean_squared_error"
      ],
      "metadata": {
        "id": "Q3370YQ9hmRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Squared Logarithmic Error, практически тоже самое, но значения предварительно логарифмируются, таким образом маленьким ошибкам также уделяется значительное внимание, обычно используется, если данным присущ экспоненциальный рост,\n",
        "\n",
        "\n",
        "sklearn.metrics.mean_squared_log_error\n",
        "Mean Absolute Percentage Error, как MAE, только в процентах, - удобно для объяснения заказчику качества прогноза,\n",
        "\n",
        "\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
      ],
      "metadata": {
        "id": "uWdqPXTXhoOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean absolute scaled error, аналог\n",
        " для временных рядов. Тоже сравнивает прогноз по вашей модели с наивным и говорит насколько он оказался лучше.\n",
        "Мы будем ниже пользоваться MAPE."
      ],
      "metadata": {
        "id": "0KlmtbJ8hqXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mape(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
      ],
      "metadata": {
        "id": "TlsF3oI6htuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sktime"
      ],
      "metadata": {
        "id": "DY3GkPqUhy8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sktime\n",
        "print(sktime.__version__)"
      ],
      "metadata": {
        "id": "yxMNCsxUhwic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разбиение данных на обучение и контроль."
      ],
      "metadata": {
        "id": "0j9gSb48h3_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.size // 24"
      ],
      "metadata": {
        "id": "B3Yza-hTh3Co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sktime.forecasting.model_selection import temporal_train_test_split\n",
        "\n",
        "y_train, y_test = temporal_train_test_split(y, test_size=48)\n",
        "plot_series(y_train, y_test, labels=[\"y_train\", \"y_test\"])\n",
        "print(y_train.shape[0], y_test.shape[0])"
      ],
      "metadata": {
        "id": "xYUdCRV2h5dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sktime.forecasting.base import ForecastingHorizon\n",
        "fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
        "fh"
      ],
      "metadata": {
        "id": "apOW5rH9h5gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Наивный прогноз\n",
        "Можно построить наивный прогноз с помощью разных стратегий. Например, как последнее значение."
      ],
      "metadata": {
        "id": "MnU4k6zrh-FZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sktime.forecasting.naive import NaiveForecaster\n",
        "\n",
        "forecaster = NaiveForecaster(strategy=\"last\")\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]);"
      ],
      "metadata": {
        "id": "pu5kQy__h_Wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mape(y_pred, y_test)"
      ],
      "metadata": {
        "id": "luNjjTDaiBW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Либо среднего за последние window_length наблюдени"
      ],
      "metadata": {
        "id": "Hxyp20WAiCl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forecaster = NaiveForecaster(strategy=\"mean\", window_length=48)\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]);"
      ],
      "metadata": {
        "id": "CRHGAQ8BiEAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mape(y_pred, y_test)"
      ],
      "metadata": {
        "id": "TYl3mWuqiFdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно с помощью сезонного последнего значения."
      ],
      "metadata": {
        "id": "Q2c9hjZ8iJvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forecaster = NaiveForecaster(strategy=\"last\", sp=24)\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]);"
      ],
      "metadata": {
        "id": "vOLKhy_-iJGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mape(y_pred, y_test)"
      ],
      "metadata": {
        "id": "I91l3weDh5iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Самый лучший из наивных прогнозов, в виде последнего сезонного значения, мы и будем использовать в качестве базового решения. Обратите внимание, что если бы модель содержала тренд, было бы логично как-то учесть его в вашем наивном прогнозе. Иначе любая модель будет его превосходить по качеству, что не очень честно."
      ],
      "metadata": {
        "id": "F25Z8kv0iOSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. ETS - модели\n",
        "ETS(ANN)"
      ],
      "metadata": {
        "id": "FkhgupVriRFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
        "\n",
        "# ETS(ANN)   старое название: Simple exponential smoothing\n",
        "forecaster = ExponentialSmoothing()\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]);"
      ],
      "metadata": {
        "id": "fbIuYU9yiRjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mape(y_test, y_pred)"
      ],
      "metadata": {
        "id": "sFbQ_tfHiP_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecaster.get_fitted_params()"
      ],
      "metadata": {
        "id": "tHjN7SuVh5lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если попросить интервальные прогнозы, пакет скажет, что они не реализованы. Вы знаете как их сделать и можете попробовать реализовать для этого пакета на базе statsmodels. Как строить интервальные прогнозы в нём, мы посмотрим ниже."
      ],
      "metadata": {
        "id": "9iNOYvSIiWjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forecaster.predict(fh, return_pred_int=True, alpha=0.95)"
      ],
      "metadata": {
        "id": "gFhkvxXDiXz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ETS(AAA)"
      ],
      "metadata": {
        "id": "UeO6qrA9iZyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ETS(ANN)   старое название: Simple exponential smoothing\n",
        "forecaster = ExponentialSmoothing(trend=\"add\", seasonal=\"add\", sp=24)\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "y_pred = forecaster.predict(fh)\n",
        "\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]);"
      ],
      "metadata": {
        "id": "7cxhMoJFibRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mape(y_test, y_pred)"
      ],
      "metadata": {
        "id": "Mx9RiuEnif0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecaster.get_fitted_params()"
      ],
      "metadata": {
        "id": "9QDJpYSHieuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auto-ETS\n",
        "Можно перебрать все ETS модели и выбрать лучшую по какому-то критерию."
      ],
      "metadata": {
        "id": "Z1pfxHpiiiRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sktime.forecasting.ets import AutoETS\n",
        "\n",
        "# Делаем перебор и выбираем лучшую модель по информационному критерию\n",
        "forecaster = AutoETS(auto=True, n_jobs=-1, information_criterion='bic')\n",
        "forecaster.fit(y_train)\n",
        "\n",
        "y_pred = forecaster.predict(fh)\n",
        "plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"]);"
      ],
      "metadata": {
        "id": "jZfS5KzLh5nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mape(y_test, y_pred)"
      ],
      "metadata": {
        "id": "2FRFP8b4h5qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Доверительные интервалы\n",
        "К сожалению, в рамках sktime доверительные интервалы для ETS-моделей ещё не реализованы. Вы можете помочь развитию пакета и реализовать их самостоятельно! :)\n",
        "\n",
        "Сейчас ETS-модель опирается в этом пакете на модуль exponential_smoothing из пакета statsmodels. В нём доверительные интервалы не предусмотрены. В этом же пакете есть модуль statespace. Там доверительные интервалы уже есть."
      ],
      "metadata": {
        "id": "bOa5E-huim70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "ets_aaa = sm.tsa.statespace.ExponentialSmoothing(y_train, trend=True, seasonal=24)\n",
        "ets_aaa_res = ets_aaa.fit()\n",
        "print(ets_aaa_res.summary())"
      ],
      "metadata": {
        "id": "tQP0ThmLioYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = 48 # test_size\n",
        "df_forecast = ets_aaa_res.get_forecast(h).summary_frame()\n",
        "df_forecast.index = fh\n",
        "df_forecast.head()"
      ],
      "metadata": {
        "id": "JjEJyBI6ip8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plot_series(y_train, y_test, df_forecast['mean'], labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
        "ax.fill_between(\n",
        "    ax.get_lines()[-1].get_xdata(),\n",
        "    df_forecast[\"mean_ci_lower\"],\n",
        "    df_forecast[\"mean_ci_upper\"],\n",
        "    alpha=0.2,\n",
        "    color=ax.get_lines()[-1].get_c(),\n",
        "    label=f\"95% prediction intervals\",\n",
        ")\n",
        "ax.legend(loc='lower left');"
      ],
      "metadata": {
        "id": "RyPp4Dusip_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mape(y_test, df_forecast['mean'])"
      ],
      "metadata": {
        "id": "nozedISbiqBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Диагностика модели\n",
        "Чтобы доверительный интервалы были корректными, надо чтобы выполнялись предпосылки модели. Ошибки должны быть независимо нормально распределены с нулевым средним и одинаковой дисперсией. Давайте посмотрим на них"
      ],
      "metadata": {
        "id": "vn29ZjIkivPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ets_aaa_res.plot_diagnostics(figsize=(10, 8));"
      ],
      "metadata": {
        "id": "DJeU3zkTiqEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Левый верхний график показывает динамику остатков во времени вокруг среднего. Мы видим, что математическое ожидание действительно совпадает с нулём. С дисперсией также всё в норме.\n",
        "\n",
        "Правый нижний график называется коррелелограмма. По данным считается автокорреляция\n",
        ". Голубым нарисован доверительный интервал для этих корреляций. Если корреляция лежит внутри интервала, гипотеза о её равенстве нулю не отвергается. Судя по всему\n",
        " и\n",
        " ненулевые. Это может быть связано с тем, что мы некорректно задали параметры, которые отвечают за сезонность.\n",
        "\n",
        "На второстепенной диагонали находится распределение остатков и диаграмма квантиль-квантиль. Хвосты распределения оказываются тяжёлыми.\n",
        "\n",
        "Выполнения предпосылок модели можно попытаться добиться, поперебирав гиперпараметры модели. Либо можно попробовать сделать остатки более похожими на нормальные, сделав для исходного ряда преобразование Бокса-Кокса.\n",
        "\n",
        "Если нас не интересуют интервальные прогнозы, а интересуют только точечные, можно не добавиваться выполнения предпосылки о нормальности. Также можно заменить нормальное распределение ошибок на какое-то другое и заняться максимизацией своей собственной функции правдоподобия. Правда придётся реализовать её вручную по аналогии с тем, что мы делали на неделе про правдоподобие."
      ],
      "metadata": {
        "id": "5bQJDWjlizNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Кросс-валидация\n",
        "Выше мы оценивали модель на тренировочном периоде, а дальше строили прогноз на весь тестовый. Дальше мы считали ошибку. Это не очень корректно, так как строить прогноз на неделю вперёд сложнее, чем на сутки вперёд.\n",
        "\n",
        "Гораздо корректнее сделать кросс-валидацию со скользящим окном и сравнить модели между собой на разных горизонтах прогнозирования."
      ],
      "metadata": {
        "id": "jDiKJ3Kgi1TF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit"
      ],
      "metadata": {
        "id": "BUBvV2GEi23U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим в документацию. Там пишут, что размер тренировочных выборок на -ой итерации:\n",
        "i * n_samples // (n_splits + 1) + n_samples % (n_splits + 1)\n",
        "\n",
        "Размер тестовой выборки на -ой итерации:\n",
        "\n",
        "n_samples//(n_splits + 1)"
      ],
      "metadata": {
        "id": "U1135GTmi48x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = np.arange(10)\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=3) #, max_train_size=5)\n",
        "\n",
        "for train_index, test_index in tscv.split(z):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
      ],
      "metadata": {
        "id": "_plwMGiBiqGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Настроим разбиение так, чтобы в тесте всегда было 7 наблюдений."
      ],
      "metadata": {
        "id": "tP2M7WpIi-Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = y.size\n",
        "n_splits = y.size // 8\n",
        "\n",
        "# начинаем строить модель с 27 наблюдения\n",
        "n_samples // (n_splits + 1) + n_samples % (n_splits + 1)"
      ],
      "metadata": {
        "id": "v8f1XMryiqJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# в тесте каждый раз по 7 наблюдений\n",
        "n_samples//(n_splits + 1)"
      ],
      "metadata": {
        "id": "hSW3YpVojAwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "n_splits = y.size // 8          # для того, чтобы в тесте каждый раз было 7 наблюдений\n",
        "h = n_samples//(n_splits + 1)   # число наблюдений в тестовой выборке\n",
        "\n",
        "M = defaultdict(list) # для метрик\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    return np.abs((y_true - y_pred) / y_true)* 100\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "for train, test in tscv.split(y):\n",
        "    y_tr, y_ts = y[train].values, y[test].values\n",
        "\n",
        "    # Первая модель\n",
        "    model = sm.tsa.statespace.ExponentialSmoothing(y_tr, trend=True, seasonal=24).fit()\n",
        "    y_hat = model.get_forecast(h).summary_frame()['mean']\n",
        "    M['ETS(A A A)'].append(mape(y_ts, y_hat.values))\n",
        "\n",
        "    # Вторая модель\n",
        "    model = sm.tsa.statespace.ExponentialSmoothing(y_tr, trend=True, seasonal=24, damped_trend=True).fit()\n",
        "    y_hat = model.get_forecast(h).summary_frame()['mean']\n",
        "    M['ETS(A Ad A)'].append(mape(y_ts, y_hat.values))"
      ],
      "metadata": {
        "id": "MmWJHvhXjC-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ошибки при кросс-валидации из текущей точки на 7 дней вперёд\n",
        "np.array(M['ETS(A A A)'])"
      ],
      "metadata": {
        "id": "2wasPqG0jEap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "for m in M.keys():\n",
        "    plt.plot(np.arange(1,h+1),np.array(M[m]).mean(axis=0), label=m)\n",
        "\n",
        "plt.xlabel('Горизонт прогнозирования', fontsize=16)\n",
        "plt.ylabel('MAPE', fontsize=16)\n",
        "plt.legend(fontsize=16);"
      ],
      "metadata": {
        "id": "S2K39uugjGAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, что на  дня модели прогнозируют примерно одинаково, а дальше качество расходится."
      ],
      "metadata": {
        "id": "6uqhWgmKjH2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. LOO кросс-валидация\n",
        "LOO кросс-валидацию можно сделать более элегантно, с помощью оконных функций в pandas."
      ],
      "metadata": {
        "id": "xWXVd_r-jKlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def timeseries_cv(y, metric=mape, treshhold=0.8):\n",
        "\n",
        "    # последний день всегда в тестовой выборке\n",
        "    y_train = y[:-1].values\n",
        "    y_test = y[-1:].values\n",
        "\n",
        "    # на каждой выборке обучаем модель\n",
        "    model = sm.tsa.statespace.ExponentialSmoothing(y_train, trend=True, seasonal=24)\n",
        "    res = model.fit()\n",
        "\n",
        "    # делаем прогноз и находим качество прогноза\n",
        "    y_hat = res.get_forecast(1).summary_frame()['mean']\n",
        "    return metric(y_test, y_hat)"
      ],
      "metadata": {
        "id": "r8sRmly2jJgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция прогнозирует на день вперёд и вычисляет ошибку."
      ],
      "metadata": {
        "id": "uw4g9BDPjOxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries_cv(y)"
      ],
      "metadata": {
        "id": "tTgnIcCEjN_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_period = int(0.8*y.size)"
      ],
      "metadata": {
        "id": "GA_6WOs9jR9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# расширяющееся окно\n",
        "quality = y.expanding(min_period).apply(lambda x: timeseries_cv(x))\n",
        "quality.dropna().mean()"
      ],
      "metadata": {
        "id": "ZAE0u098jTP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# скользящее окно\n",
        "quality = y.rolling(min_period).apply(lambda x: timeseries_cv(x))\n",
        "quality.dropna().mean()"
      ],
      "metadata": {
        "id": "NbFc438ujUaP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}